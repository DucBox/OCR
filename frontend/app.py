import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
import numpy as np
import cv2
import io
from PIL import Image
import pillow_heif
import tempfile

# Import cÃ¡c module xá»­ lÃ½
from src.config import THRESHOLD
from src.config import CORNER_MODEL_PATH, TEXT_MODEL_PATH, VIETOCR_MODEL_PATH, FACE_DETECTION_MODEL_PATH
from src.utils import detect, embed_facenet, compute_similarity
from src.face_embedding import embedding
from src.face_verification import embed_face_cccd, verify_identity
from src.card_detection import detect_corners
from src.transform_card import process_card_transformation
from src.text_detection import detect_text_regions
from src.text_recognition import load_vietocr, extract_text_from_boxes
from src.database import save_embeddings_to_firestore, get_embeddings_from_firestore
st.title("ğŸ†” Face Verification & CCCD Extraction")

# âœ… Cache models Ä‘á»ƒ tá»‘i Æ°u
@st.cache_resource
def get_corner_model():
    from ultralytics import YOLO
    return YOLO(CORNER_MODEL_PATH)

@st.cache_resource
def get_text_model():
    from ultralytics import YOLO
    return YOLO(TEXT_MODEL_PATH)

@st.cache_resource
def get_face_model():
    from ultralytics import YOLO
    return YOLO(FACE_DETECTION_MODEL_PATH)

@st.cache_resource
def get_facenet_model():
    from facenet_pytorch import InceptionResnetV1
    return InceptionResnetV1(pretrained="vggface2").eval()

@st.cache_resource
def get_ocr_model():
    return load_vietocr()

# ğŸ  Load cÃ¡c model chá»‰ má»™t láº§n
corner_model = get_corner_model()
text_model = get_text_model()
face_model = get_face_model()
facenet_model = get_facenet_model()
ocr_model = get_ocr_model()

# ğŸ”„ Session state Ä‘á»ƒ kiá»ƒm soÃ¡t hiá»ƒn thá»‹ pháº§n CCCD
if "embeddings_done" not in st.session_state:
    st.session_state.embeddings_done = False
    
# ğŸ“Œ User nháº­p ID cá»§a há»
user_id = st.text_input("ğŸ”‘ Nháº­p User ID:", placeholder="Nháº­p mÃ£ Ä‘á»‹nh danh cá»§a báº¡n")
st.write(f"Welcome {user_id} to my web")

# âœ… Upload video Ä‘á»ƒ táº¡o embeddings
st.subheader("ğŸ¥ Upload Video Ä‘á»ƒ táº¡o Face Embeddings")
video_file = st.file_uploader("ğŸ“‚ **Chá»n video**", type=["mp4", "avi", "mov"])

if video_file is not None and not st.session_state.get("embeddings_done", False):
    st.write("ğŸ“Œ **Äang xá»­ lÃ½ video...**")

    # âœ… LÆ°u file video vÃ o má»™t tá»‡p táº¡m thá»i
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
        temp_video.write(video_file.read())
        temp_video_path = temp_video.name  # Láº¥y Ä‘Æ°á»ng dáº«n tá»‡p táº¡m

    # âœ… Má»Ÿ video báº±ng OpenCV
    video_cap = cv2.VideoCapture(temp_video_path)

    if not video_cap.isOpened():
        st.error("âŒ KhÃ´ng thá»ƒ má»Ÿ video! HÃ£y thá»­ upload láº¡i.")
        st.stop()
    else:
        st.success("âœ… Video Ä‘Ã£ Ä‘Æ°á»£c má»Ÿ thÃ nh cÃ´ng!")

    # ğŸŸ¢ Cháº¡y pipeline embedding
    embeddings = embedding(face_model, facenet_model, video_cap)

    if not embeddings:
        st.error("âŒ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t embeddings tá»« video! HÃ£y chá»n video khÃ¡c.")
        st.stop()

    save_embeddings_to_firestore(user_id, embeddings)
    
    st.success(f"âœ… ÄÃ£ lÆ°u embeddings thÃ nh cÃ´ng cho user `{user_id}`!")
    st.session_state.embeddings_done = True  # âœ… ÄÃ¡nh dáº¥u Ä‘Ã£ táº¡o embeddings

    # XÃ³a message sau khi cháº¡y xong
    st.rerun()

# âœ… Chá»‰ hiá»ƒn thá»‹ pháº§n CCCD náº¿u embeddings Ä‘Ã£ táº¡o xong
if st.session_state.embeddings_done:
    st.subheader("ğŸ“¸ Upload áº£nh CCCD Ä‘á»ƒ xÃ¡c thá»±c")
    uploaded_file = st.file_uploader("ğŸ“‚ **Chá»n áº£nh CCCD**", type=["jpg", "jpeg", "png", "HEIC"])

    if uploaded_file is not None:
        st.write("ğŸ“Œ **Äang xá»­ lÃ½ áº£nh CCCD...**")

        # ğŸŸ¢ Äá»c áº£nh (há»— trá»£ HEIC)
        try:
            if uploaded_file.name.lower().endswith(".heic"):
                heif_image = pillow_heif.open_heif(uploaded_file)
                image = Image.frombytes(heif_image.mode, heif_image.size, heif_image.data)
            else:
                image = Image.open(uploaded_file)
            image = image.convert("RGB")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi Ä‘á»c áº£nh: {e}")
            st.stop()

        # Chuyá»ƒn áº£nh sang numpy array
        image_np = np.array(image)

        # ğŸ” Embed khuÃ´n máº·t tá»« áº£nh CCCD
        status = st.empty()  # ğŸ‘ˆ Táº¡o placeholder Ä‘á»ƒ xÃ³a tráº¡ng thÃ¡i sau khi cháº¡y xong
        face_embedding_cccd, error = embed_face_cccd(face_model, facenet_model, image_np)
        # status.empty()  # âŒ XÃ³a dÃ²ng tráº¡ng thÃ¡i
        if error:
            st.error(error)  # Hiá»ƒn thá»‹ lá»—i trÃªn UI
            st.stop()
        
        user_embeddings = get_embeddings_from_firestore(user_id)
        if user_embeddings is None:
            st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y embeddings cá»§a user `{user_id}`!")
            st.stop()

        # ğŸ” So sÃ¡nh vá»›i embeddings tá»« video
        status = st.empty()
        status.write("ğŸ” **Äang xÃ¡c thá»±c danh tÃ­nh...**")
        verified, max_similarity = verify_identity(face_embedding_cccd, user_embeddings, threshold = THRESHOLD)
        # status.empty()

        st.write(f"ğŸ“Š **Cosine Similarity:** {max_similarity:.4f}")

        if not verified:
            st.error("âŒ **XÃ¡c thá»±c tháº¥t báº¡i!** KhuÃ´n máº·t khÃ´ng khá»›p.")
            st.stop()

        st.success("âœ… **XÃ¡c thá»±c thÃ nh cÃ´ng!** Tiáº¿p tá»¥c trÃ­ch xuáº¥t thÃ´ng tin CCCD.")

        # ğŸ” Nháº­n diá»‡n gÃ³c CCCD
        status = st.empty()
        status.write("ğŸ” **Äang nháº­n diá»‡n 4 gÃ³c CCCD...**")
        filtered_corners, corner_centers = detect_corners(corner_model, image_np)
        status.empty()

        if not filtered_corners:
            st.error("ğŸš¨ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c Ä‘á»§ 4 gÃ³c tháº» CCCD!")
            st.stop()

        # ğŸ“ Transform perspective
        status = st.empty()
        status.write("ğŸ“ **Äang xá»­ lÃ½ perspective transformation...**")
        transformed_image = process_card_transformation(image_np, corner_centers)
        status.empty()

        if transformed_image is None:
            st.error("ğŸš¨ KhÃ´ng thá»ƒ chuyá»ƒn Ä‘á»•i gÃ³c áº£nh!")
            st.stop()

        # ğŸ“ PhÃ¡t hiá»‡n vÃ¹ng chá»©a text
        status = st.empty()
        status.write("ğŸ“ **Äang phÃ¡t hiá»‡n vÃ¹ng chá»©a vÄƒn báº£n...**")
        text_boxes = detect_text_regions(text_model, transformed_image)
        status.empty()

        if not text_boxes:
            st.error("ğŸš¨ KhÃ´ng tÃ¬m tháº¥y vÃ¹ng vÄƒn báº£n nÃ o!")
            st.stop()

        # ğŸ”  TrÃ­ch xuáº¥t vÄƒn báº£n
        status = st.empty()
        status.write("ğŸ”  **Äang nháº­n diá»‡n vÄƒn báº£n...**")
        extracted_texts = extract_text_from_boxes(transformed_image, text_boxes, ocr_model)
        status.empty()

        if not extracted_texts or all(v == "N/A" for v in extracted_texts.values()):
            st.error("ğŸš¨ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c vÄƒn báº£n!")
            st.stop()

        # âœ¨ Hiá»ƒn thá»‹ káº¿t quáº£
        st.subheader("ğŸ“‹ ThÃ´ng tin trÃ­ch xuáº¥t:")
        st.write(f"**ğŸ†” Sá»‘ CCCD:** {extracted_texts.get('id', 'N/A')}")
        st.write(f"**ğŸ‘¤ Há» vÃ  tÃªn:** {extracted_texts.get('name', 'N/A')}")
        st.write(f"**ğŸ“… NgÃ y sinh:** {extracted_texts.get('birth', 'N/A')}")

        st.success("âœ… **HoÃ n táº¥t!**")
