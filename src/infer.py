import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
import cv2
import matplotlib.pyplot as plt
from src.config import CORNER_MODEL_PATH, TEXT_MODEL_PATH, VIETOCR_MODEL_PATH
from src.card_detection import load_yolo_model, detect_corners
from src.transform_card import perspective_transform
from src.text_detection import detect_text_regions
from src.text_recognition import load_vietocr, extract_text_from_boxes

# ÄÆ°á»ng dáº«n áº£nh test (Cáº­p nháº­t áº£nh cá»¥ thá»ƒ)
IMAGE_PATH = "/Users/ngoquangduc/Desktop/AI_Project/Card_ID/data/raw/IMG_2215.JPG"

def main():
    print("\nğŸš€ [INFO] Starting Inference...\n")

    # ğŸ”¹ Load YOLO model
    print(f"ğŸ“‚ [INFO] Loading corner detection model from: {CORNER_MODEL_PATH}")
    corner_model = load_yolo_model(CORNER_MODEL_PATH)

    print(f"ğŸ“‚ [INFO] Loading text detection model from: {TEXT_MODEL_PATH}")
    text_model = load_yolo_model(TEXT_MODEL_PATH)

    # ğŸ”¹ Load image
    print(f"ğŸ–¼ [INFO] Loading image: {IMAGE_PATH}")
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        print("âŒ [ERROR] Failed to load image. Check the file path.")
        return

    # ğŸ”¹ Detect corners
    print("ğŸ” [INFO] Running corner detection...")
    filtered_corners, corner_centers = detect_corners(corner_model, image)
    print(f"âœ… [INFO] Detected corners: {filtered_corners}")

    if not filtered_corners:
        print("âŒ [ERROR] No corners detected. Exiting.")
        return

    # ğŸ”¹ Perspective Transform
    print("ğŸ“ [INFO] Performing perspective transform...")
    transformed_image = perspective_transform(image, corner_centers)
    if transformed_image is None:
        print("âŒ [ERROR] Perspective transformation failed. Exiting.")
        return

    # ğŸ”¹ Detect text regions
    print("ğŸ“ [INFO] Running text region detection...")
    text_boxes = detect_text_regions(text_model, transformed_image)
    if not text_boxes:
        print("âš ï¸ [WARNING] No text regions detected.")

    # ğŸ”¹ Load VietOCR model
    print(f"ğŸ“‚ [INFO] Loading OCR model from: {VIETOCR_MODEL_PATH}")
    vietocr_detector = load_vietocr()

    # ğŸ”¹ Extract text
    if text_boxes:
        print("ğŸ”  [INFO] Running OCR to extract text...")
        extracted_texts = extract_text_from_boxes(transformed_image, text_boxes, vietocr_detector)
    else:
        extracted_texts = {}

    # ğŸ”¹ Print extracted information
    print("\nğŸ¯ [RESULT] Extracted Information:")
    print(f"ğŸ†” ID: {extracted_texts.get('id', 'N/A')}")
    print(f"ğŸ‘¤ Name: {extracted_texts.get('name', 'N/A')}")
    print(f"ğŸ“… Birth: {extracted_texts.get('birth', 'N/A')}")

if __name__ == "__main__":
    main()
